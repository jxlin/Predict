{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_set = pd.read_csv('TimeBasedFeatures-Dataset-15s-AllinOne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature in combined_set.columns: # Loop through all columns in the dataframe\n",
    "    if combined_set[feature].dtype == 'object': # Only apply for columns with categorical strings\n",
    "        combined_set[feature] = pd.Categorical(combined_set[feature]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = combined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled = data2.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = shuffled.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = shuffled.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainsize = int(len(shuffled['class1']) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testsize = len(shuffled['class1']) - trainsize\n",
    "npredictors = len(predictors.columns)\n",
    "noutputs = 1\n",
    "numiter = 10000\n",
    "modelfile = '/tmp/trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (15006, 23) (15006, 7)\n",
      "Validation set (1876, 23) (1876, 7)\n",
      "Test set (1876, 23) (1876, 7)\n",
      "Training set (15006, 23) (15006, 7)\n",
      "Validation set (1876, 23) (1876, 7)\n",
      "Test set (1876, 23) (1876, 7)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "image_size = 23\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.values\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(predictors[:trainsize], targets[:trainsize])\n",
    "valid_dataset, valid_labels = reformat(predictors[trainsize:trainsize + testsize / 2], targets[trainsize:trainsize + testsize / 2])\n",
    "test_dataset, test_labels = reformat(predictors[trainsize + testsize / 2:], targets[trainsize + testsize / 2:])\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_subset = 15006\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :].astype(np.float32))\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset.astype(np.float32))\n",
    "  tf_test_dataset = tf.constant(test_dataset.astype(np.float32))\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 15968755.000000\n",
      "Training accuracy: 30.9%\n",
      "Validation accuracy: 26.4%\n",
      "Initialized\n",
      "Loss at step 0: 15968755.000000\n",
      "Training accuracy: 30.9%\n",
      "Validation accuracy: 26.4%\n",
      "Loss at step 100: 3065381126144.000000\n",
      "Training accuracy: 47.1%\n",
      "Validation accuracy: 32.5%\n",
      "Loss at step 100: 3065381126144.000000\n",
      "Training accuracy: 47.1%\n",
      "Validation accuracy: 32.5%\n",
      "Loss at step 200: 15248485515264.000000\n",
      "Training accuracy: 35.5%\n",
      "Validation accuracy: 41.6%\n",
      "Loss at step 200: 15248485515264.000000\n",
      "Training accuracy: 35.5%\n",
      "Validation accuracy: 41.6%\n",
      "Loss at step 300: 4114921029632.000000\n",
      "Training accuracy: 48.7%\n",
      "Validation accuracy: 48.3%\n",
      "Loss at step 300: 4114921029632.000000\n",
      "Training accuracy: 48.7%\n",
      "Validation accuracy: 48.3%\n",
      "Loss at step 400: 13390432960512.000000\n",
      "Training accuracy: 55.1%\n",
      "Validation accuracy: 24.1%\n",
      "Loss at step 400: 13390432960512.000000\n",
      "Training accuracy: 55.1%\n",
      "Validation accuracy: 24.1%\n",
      "Loss at step 500: 4474676969472.000000\n",
      "Training accuracy: 50.0%\n",
      "Validation accuracy: 42.7%\n",
      "Loss at step 500: 4474676969472.000000\n",
      "Training accuracy: 50.0%\n",
      "Validation accuracy: 42.7%\n",
      "Loss at step 600: 4964877860864.000000\n",
      "Training accuracy: 45.3%\n",
      "Validation accuracy: 56.4%\n",
      "Loss at step 600: 4964877860864.000000\n",
      "Training accuracy: 45.3%\n",
      "Validation accuracy: 56.4%\n",
      "Loss at step 700: 9989921964032.000000\n",
      "Training accuracy: 52.3%\n",
      "Validation accuracy: 37.7%\n",
      "Loss at step 700: 9989921964032.000000\n",
      "Training accuracy: 52.3%\n",
      "Validation accuracy: 37.7%\n",
      "Loss at step 800: 3553349074944.000000\n",
      "Training accuracy: 43.8%\n",
      "Validation accuracy: 53.4%\n",
      "Test accuracy: 53.3%\n",
      "Loss at step 800: 3553349074944.000000\n",
      "Training accuracy: 43.8%\n",
      "Validation accuracy: 53.4%\n",
      "Test accuracy: 53.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "with tf.Session(graph=graph) as session: \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_labels[:train_subset, :]))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "graph = tf.Graph()\n",
    "train_dataset = train_dataset.astype(np.float32)\n",
    "valid_dataset = valid_dataset.astype(np.float32)\n",
    "test_dataset = test_dataset.astype(np.float32)\n",
    "with graph.as_default():\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 41860256.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 48.9%\n",
      "Initialized\n",
      "Minibatch loss at step 0: 41860256.000000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 48.9%\n",
      "Minibatch loss at step 500: 26188967837696.000000\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 47.7%\n",
      "Minibatch loss at step 500: 26188967837696.000000\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 47.7%\n",
      "Minibatch loss at step 1000: 14405175607296.000000\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 24.8%\n",
      "Minibatch loss at step 1000: 14405175607296.000000\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 24.8%\n",
      "Minibatch loss at step 1500: 5069009321984.000000\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 42.1%\n",
      "Minibatch loss at step 1500: 5069009321984.000000\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 42.1%\n",
      "Minibatch loss at step 2000: 7049229369344.000000\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 47.8%\n",
      "Minibatch loss at step 2000: 7049229369344.000000\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 47.8%\n",
      "Minibatch loss at step 2500: 5404002091008.000000\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 51.3%\n",
      "Minibatch loss at step 2500: 5404002091008.000000\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 51.3%\n",
      "Minibatch loss at step 3000: 5115023458304.000000\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 47.3%\n",
      "Test accuracy: 48.5%\n",
      "Minibatch loss at step 3000: 5115023458304.000000\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 47.3%\n",
      "Test accuracy: 48.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('TimeBasedFeatures-Dataset-15s-AllinOne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18758 entries, 0 to 18757\n",
      "Data columns (total 24 columns):\n",
      "duration              18758 non-null int64\n",
      "total_fiat            18758 non-null int64\n",
      "total_biat            18758 non-null int64\n",
      "min_fiat              18758 non-null int64\n",
      "min_biat              18758 non-null int64\n",
      "max_fiat              18758 non-null float64\n",
      "max_biat              18758 non-null float64\n",
      "mean_fiat             18758 non-null float64\n",
      "mean_biat             18758 non-null float64\n",
      "flowPktsPerSecond     18758 non-null float64\n",
      "flowBytesPerSecond    18758 non-null float64\n",
      "min_flowiat           18758 non-null int64\n",
      "max_flowiat           18758 non-null int64\n",
      "mean_flowiat          18758 non-null float64\n",
      "std_flowiat           18758 non-null float64\n",
      "min_active            18758 non-null int64\n",
      "mean_active           18758 non-null float64\n",
      "max_active            18758 non-null int64\n",
      "std_active            18758 non-null float64\n",
      "min_idle              18758 non-null int64\n",
      "mean_idle             18758 non-null float64\n",
      "max_idle              18758 non-null int64\n",
      "std_idle              18758 non-null float64\n",
      "class1                18758 non-null object\n",
      "dtypes: float64(12), int64(11), object(1)\n",
      "memory usage: 3.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18758 entries, 0 to 18757\n",
      "Data columns (total 24 columns):\n",
      "duration              18758 non-null int64\n",
      "total_fiat            18758 non-null int64\n",
      "total_biat            18758 non-null int64\n",
      "min_fiat              18758 non-null int64\n",
      "min_biat              18758 non-null int64\n",
      "max_fiat              18758 non-null float64\n",
      "max_biat              18758 non-null float64\n",
      "mean_fiat             18758 non-null float64\n",
      "mean_biat             18758 non-null float64\n",
      "flowPktsPerSecond     18758 non-null float64\n",
      "flowBytesPerSecond    18758 non-null float64\n",
      "min_flowiat           18758 non-null int64\n",
      "max_flowiat           18758 non-null int64\n",
      "mean_flowiat          18758 non-null float64\n",
      "std_flowiat           18758 non-null float64\n",
      "min_active            18758 non-null int64\n",
      "mean_active           18758 non-null float64\n",
      "max_active            18758 non-null int64\n",
      "std_active            18758 non-null float64\n",
      "min_idle              18758 non-null int64\n",
      "mean_idle             18758 non-null float64\n",
      "max_idle              18758 non-null int64\n",
      "std_idle              18758 non-null float64\n",
      "class1                18758 non-null object\n",
      "dtypes: float64(12), int64(11), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "d1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>total_fiat</th>\n",
       "      <th>total_biat</th>\n",
       "      <th>min_fiat</th>\n",
       "      <th>min_biat</th>\n",
       "      <th>max_fiat</th>\n",
       "      <th>max_biat</th>\n",
       "      <th>mean_fiat</th>\n",
       "      <th>mean_biat</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_flowiat</th>\n",
       "      <th>std_flowiat</th>\n",
       "      <th>min_active</th>\n",
       "      <th>mean_active</th>\n",
       "      <th>max_active</th>\n",
       "      <th>std_active</th>\n",
       "      <th>min_idle</th>\n",
       "      <th>mean_idle</th>\n",
       "      <th>max_idle</th>\n",
       "      <th>std_idle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>18758.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.791705e+06</td>\n",
       "      <td>6.086783e+05</td>\n",
       "      <td>6.267802e+05</td>\n",
       "      <td>3.314204e+06</td>\n",
       "      <td>2.861716e+06</td>\n",
       "      <td>1.003929e+06</td>\n",
       "      <td>9.218250e+05</td>\n",
       "      <td>8.448286e+05</td>\n",
       "      <td>6.133578e+05</td>\n",
       "      <td>2073.780095</td>\n",
       "      <td>...</td>\n",
       "      <td>4.768167e+05</td>\n",
       "      <td>1.035025e+06</td>\n",
       "      <td>3.253846e+06</td>\n",
       "      <td>3.635654e+06</td>\n",
       "      <td>4.091204e+06</td>\n",
       "      <td>5.025001e+05</td>\n",
       "      <td>2.983753e+06</td>\n",
       "      <td>3.325142e+06</td>\n",
       "      <td>3.732466e+06</td>\n",
       "      <td>4.531389e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.438458e+07</td>\n",
       "      <td>2.243195e+06</td>\n",
       "      <td>2.326442e+06</td>\n",
       "      <td>1.062115e+07</td>\n",
       "      <td>9.652561e+06</td>\n",
       "      <td>3.141855e+06</td>\n",
       "      <td>2.495984e+06</td>\n",
       "      <td>4.336559e+06</td>\n",
       "      <td>2.516395e+06</td>\n",
       "      <td>19115.713624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.404428e+06</td>\n",
       "      <td>3.534085e+06</td>\n",
       "      <td>1.342955e+07</td>\n",
       "      <td>1.356162e+07</td>\n",
       "      <td>1.400211e+07</td>\n",
       "      <td>2.813959e+06</td>\n",
       "      <td>1.334323e+07</td>\n",
       "      <td>1.347430e+07</td>\n",
       "      <td>1.390155e+07</td>\n",
       "      <td>2.785573e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.346690e+05</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.597050e+04</td>\n",
       "      <td>2.454225e+04</td>\n",
       "      <td>1.154333e+04</td>\n",
       "      <td>5.626786e+03</td>\n",
       "      <td>1.145469e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.599190</td>\n",
       "      <td>...</td>\n",
       "      <td>9.577449e+03</td>\n",
       "      <td>5.574602e+03</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.109263e+07</td>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>2.821430e+05</td>\n",
       "      <td>2.865800e+05</td>\n",
       "      <td>5.104959e+04</td>\n",
       "      <td>3.526250e+04</td>\n",
       "      <td>1.164916e+04</td>\n",
       "      <td>9.605910e+03</td>\n",
       "      <td>11.681220</td>\n",
       "      <td>...</td>\n",
       "      <td>8.412602e+04</td>\n",
       "      <td>7.518175e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.494537e+07</td>\n",
       "      <td>1.645000e+03</td>\n",
       "      <td>1.651000e+03</td>\n",
       "      <td>4.289454e+06</td>\n",
       "      <td>4.265465e+06</td>\n",
       "      <td>5.260302e+05</td>\n",
       "      <td>4.843726e+05</td>\n",
       "      <td>6.055940e+05</td>\n",
       "      <td>5.340370e+05</td>\n",
       "      <td>100.671695</td>\n",
       "      <td>...</td>\n",
       "      <td>3.119330e+05</td>\n",
       "      <td>7.659213e+05</td>\n",
       "      <td>2.767727e+06</td>\n",
       "      <td>4.248512e+06</td>\n",
       "      <td>5.690602e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.943930e+06</td>\n",
       "      <td>3.333185e+06</td>\n",
       "      <td>4.696002e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.014050e+08</td>\n",
       "      <td>3.768079e+07</td>\n",
       "      <td>4.300238e+07</td>\n",
       "      <td>3.035957e+08</td>\n",
       "      <td>6.001097e+08</td>\n",
       "      <td>1.520000e+08</td>\n",
       "      <td>4.300000e+07</td>\n",
       "      <td>2.150000e+08</td>\n",
       "      <td>9.800000e+07</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.070000e+07</td>\n",
       "      <td>1.360000e+08</td>\n",
       "      <td>6.014050e+08</td>\n",
       "      <td>6.010000e+08</td>\n",
       "      <td>6.014050e+08</td>\n",
       "      <td>1.680000e+08</td>\n",
       "      <td>6.001097e+08</td>\n",
       "      <td>6.000000e+08</td>\n",
       "      <td>6.001097e+08</td>\n",
       "      <td>1.680000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration    total_fiat    total_biat      min_fiat      min_biat  \\\n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04   \n",
       "mean   9.791705e+06  6.086783e+05  6.267802e+05  3.314204e+06  2.861716e+06   \n",
       "std    1.438458e+07  2.243195e+06  2.326442e+06  1.062115e+07  9.652561e+06   \n",
       "min    0.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00   \n",
       "25%    3.346690e+05  7.000000e+00  2.000000e+00  2.597050e+04  2.454225e+04   \n",
       "50%    1.109263e+07  6.200000e+01  2.100000e+01  2.821430e+05  2.865800e+05   \n",
       "75%    1.494537e+07  1.645000e+03  1.651000e+03  4.289454e+06  4.265465e+06   \n",
       "max    6.014050e+08  3.768079e+07  4.300238e+07  3.035957e+08  6.001097e+08   \n",
       "\n",
       "           max_fiat      max_biat     mean_fiat     mean_biat  \\\n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04   \n",
       "mean   1.003929e+06  9.218250e+05  8.448286e+05  6.133578e+05   \n",
       "std    3.141855e+06  2.495984e+06  4.336559e+06  2.516395e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.154333e+04  5.626786e+03  1.145469e+02  0.000000e+00   \n",
       "50%    5.104959e+04  3.526250e+04  1.164916e+04  9.605910e+03   \n",
       "75%    5.260302e+05  4.843726e+05  6.055940e+05  5.340370e+05   \n",
       "max    1.520000e+08  4.300000e+07  2.150000e+08  9.800000e+07   \n",
       "\n",
       "       flowPktsPerSecond      ...       mean_flowiat   std_flowiat  \\\n",
       "count       18758.000000      ...       1.875800e+04  1.875800e+04   \n",
       "mean         2073.780095      ...       4.768167e+05  1.035025e+06   \n",
       "std         19115.713624      ...       1.404428e+06  3.534085e+06   \n",
       "min             0.000000      ...       0.000000e+00  0.000000e+00   \n",
       "25%             2.599190      ...       9.577449e+03  5.574602e+03   \n",
       "50%            11.681220      ...       8.412602e+04  7.518175e+04   \n",
       "75%           100.671695      ...       3.119330e+05  7.659213e+05   \n",
       "max       1000000.000000      ...       6.070000e+07  1.360000e+08   \n",
       "\n",
       "         min_active   mean_active    max_active    std_active      min_idle  \\\n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04   \n",
       "mean   3.253846e+06  3.635654e+06  4.091204e+06  5.025001e+05  2.983753e+06   \n",
       "std    1.342955e+07  1.356162e+07  1.400211e+07  2.813959e+06  1.334323e+07   \n",
       "min   -1.000000e+00  0.000000e+00 -1.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "25%   -1.000000e+00  0.000000e+00 -1.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "50%   -1.000000e+00  0.000000e+00 -1.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "75%    2.767727e+06  4.248512e+06  5.690602e+06  0.000000e+00  1.943930e+06   \n",
       "max    6.014050e+08  6.010000e+08  6.014050e+08  1.680000e+08  6.001097e+08   \n",
       "\n",
       "          mean_idle      max_idle      std_idle  \n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  \n",
       "mean   3.325142e+06  3.732466e+06  4.531389e+05  \n",
       "std    1.347430e+07  1.390155e+07  2.785573e+06  \n",
       "min    0.000000e+00 -1.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00 -1.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00 -1.000000e+00  0.000000e+00  \n",
       "75%    3.333185e+06  4.696002e+06  0.000000e+00  \n",
       "max    6.000000e+08  6.001097e+08  1.680000e+08  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>total_fiat</th>\n",
       "      <th>total_biat</th>\n",
       "      <th>min_fiat</th>\n",
       "      <th>min_biat</th>\n",
       "      <th>max_fiat</th>\n",
       "      <th>max_biat</th>\n",
       "      <th>mean_fiat</th>\n",
       "      <th>mean_biat</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_flowiat</th>\n",
       "      <th>std_flowiat</th>\n",
       "      <th>min_active</th>\n",
       "      <th>mean_active</th>\n",
       "      <th>max_active</th>\n",
       "      <th>std_active</th>\n",
       "      <th>min_idle</th>\n",
       "      <th>mean_idle</th>\n",
       "      <th>max_idle</th>\n",
       "      <th>std_idle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>18758.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "      <td>1.875800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.791705e+06</td>\n",
       "      <td>6.086783e+05</td>\n",
       "      <td>6.267802e+05</td>\n",
       "      <td>3.314204e+06</td>\n",
       "      <td>2.861716e+06</td>\n",
       "      <td>1.003929e+06</td>\n",
       "      <td>9.218250e+05</td>\n",
       "      <td>8.448286e+05</td>\n",
       "      <td>6.133578e+05</td>\n",
       "      <td>2073.780095</td>\n",
       "      <td>...</td>\n",
       "      <td>4.768167e+05</td>\n",
       "      <td>1.035025e+06</td>\n",
       "      <td>3.253846e+06</td>\n",
       "      <td>3.635654e+06</td>\n",
       "      <td>4.091204e+06</td>\n",
       "      <td>5.025001e+05</td>\n",
       "      <td>2.983753e+06</td>\n",
       "      <td>3.325142e+06</td>\n",
       "      <td>3.732466e+06</td>\n",
       "      <td>4.531389e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.438458e+07</td>\n",
       "      <td>2.243195e+06</td>\n",
       "      <td>2.326442e+06</td>\n",
       "      <td>1.062115e+07</td>\n",
       "      <td>9.652561e+06</td>\n",
       "      <td>3.141855e+06</td>\n",
       "      <td>2.495984e+06</td>\n",
       "      <td>4.336559e+06</td>\n",
       "      <td>2.516395e+06</td>\n",
       "      <td>19115.713624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.404428e+06</td>\n",
       "      <td>3.534085e+06</td>\n",
       "      <td>1.342955e+07</td>\n",
       "      <td>1.356162e+07</td>\n",
       "      <td>1.400211e+07</td>\n",
       "      <td>2.813959e+06</td>\n",
       "      <td>1.334323e+07</td>\n",
       "      <td>1.347430e+07</td>\n",
       "      <td>1.390155e+07</td>\n",
       "      <td>2.785573e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.346690e+05</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.597050e+04</td>\n",
       "      <td>2.454225e+04</td>\n",
       "      <td>1.154333e+04</td>\n",
       "      <td>5.626786e+03</td>\n",
       "      <td>1.145469e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.599190</td>\n",
       "      <td>...</td>\n",
       "      <td>9.577449e+03</td>\n",
       "      <td>5.574602e+03</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.109263e+07</td>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>2.821430e+05</td>\n",
       "      <td>2.865800e+05</td>\n",
       "      <td>5.104959e+04</td>\n",
       "      <td>3.526250e+04</td>\n",
       "      <td>1.164916e+04</td>\n",
       "      <td>9.605910e+03</td>\n",
       "      <td>11.681220</td>\n",
       "      <td>...</td>\n",
       "      <td>8.412602e+04</td>\n",
       "      <td>7.518175e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.494537e+07</td>\n",
       "      <td>1.645000e+03</td>\n",
       "      <td>1.651000e+03</td>\n",
       "      <td>4.289454e+06</td>\n",
       "      <td>4.265465e+06</td>\n",
       "      <td>5.260302e+05</td>\n",
       "      <td>4.843726e+05</td>\n",
       "      <td>6.055940e+05</td>\n",
       "      <td>5.340370e+05</td>\n",
       "      <td>100.671695</td>\n",
       "      <td>...</td>\n",
       "      <td>3.119330e+05</td>\n",
       "      <td>7.659213e+05</td>\n",
       "      <td>2.767727e+06</td>\n",
       "      <td>4.248512e+06</td>\n",
       "      <td>5.690602e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.943930e+06</td>\n",
       "      <td>3.333185e+06</td>\n",
       "      <td>4.696002e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.014050e+08</td>\n",
       "      <td>3.768079e+07</td>\n",
       "      <td>4.300238e+07</td>\n",
       "      <td>3.035957e+08</td>\n",
       "      <td>6.001097e+08</td>\n",
       "      <td>1.520000e+08</td>\n",
       "      <td>4.300000e+07</td>\n",
       "      <td>2.150000e+08</td>\n",
       "      <td>9.800000e+07</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.070000e+07</td>\n",
       "      <td>1.360000e+08</td>\n",
       "      <td>6.014050e+08</td>\n",
       "      <td>6.010000e+08</td>\n",
       "      <td>6.014050e+08</td>\n",
       "      <td>1.680000e+08</td>\n",
       "      <td>6.001097e+08</td>\n",
       "      <td>6.000000e+08</td>\n",
       "      <td>6.001097e+08</td>\n",
       "      <td>1.680000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration    total_fiat    total_biat      min_fiat      min_biat  \\\n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04   \n",
       "mean   9.791705e+06  6.086783e+05  6.267802e+05  3.314204e+06  2.861716e+06   \n",
       "std    1.438458e+07  2.243195e+06  2.326442e+06  1.062115e+07  9.652561e+06   \n",
       "min    0.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00   \n",
       "25%    3.346690e+05  7.000000e+00  2.000000e+00  2.597050e+04  2.454225e+04   \n",
       "50%    1.109263e+07  6.200000e+01  2.100000e+01  2.821430e+05  2.865800e+05   \n",
       "75%    1.494537e+07  1.645000e+03  1.651000e+03  4.289454e+06  4.265465e+06   \n",
       "max    6.014050e+08  3.768079e+07  4.300238e+07  3.035957e+08  6.001097e+08   \n",
       "\n",
       "           max_fiat      max_biat     mean_fiat     mean_biat  \\\n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04   \n",
       "mean   1.003929e+06  9.218250e+05  8.448286e+05  6.133578e+05   \n",
       "std    3.141855e+06  2.495984e+06  4.336559e+06  2.516395e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.154333e+04  5.626786e+03  1.145469e+02  0.000000e+00   \n",
       "50%    5.104959e+04  3.526250e+04  1.164916e+04  9.605910e+03   \n",
       "75%    5.260302e+05  4.843726e+05  6.055940e+05  5.340370e+05   \n",
       "max    1.520000e+08  4.300000e+07  2.150000e+08  9.800000e+07   \n",
       "\n",
       "       flowPktsPerSecond      ...       mean_flowiat   std_flowiat  \\\n",
       "count       18758.000000      ...       1.875800e+04  1.875800e+04   \n",
       "mean         2073.780095      ...       4.768167e+05  1.035025e+06   \n",
       "std         19115.713624      ...       1.404428e+06  3.534085e+06   \n",
       "min             0.000000      ...       0.000000e+00  0.000000e+00   \n",
       "25%             2.599190      ...       9.577449e+03  5.574602e+03   \n",
       "50%            11.681220      ...       8.412602e+04  7.518175e+04   \n",
       "75%           100.671695      ...       3.119330e+05  7.659213e+05   \n",
       "max       1000000.000000      ...       6.070000e+07  1.360000e+08   \n",
       "\n",
       "         min_active   mean_active    max_active    std_active      min_idle  \\\n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04  1.875800e+04   \n",
       "mean   3.253846e+06  3.635654e+06  4.091204e+06  5.025001e+05  2.983753e+06   \n",
       "std    1.342955e+07  1.356162e+07  1.400211e+07  2.813959e+06  1.334323e+07   \n",
       "min   -1.000000e+00  0.000000e+00 -1.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "25%   -1.000000e+00  0.000000e+00 -1.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "50%   -1.000000e+00  0.000000e+00 -1.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "75%    2.767727e+06  4.248512e+06  5.690602e+06  0.000000e+00  1.943930e+06   \n",
       "max    6.014050e+08  6.010000e+08  6.014050e+08  1.680000e+08  6.001097e+08   \n",
       "\n",
       "          mean_idle      max_idle      std_idle  \n",
       "count  1.875800e+04  1.875800e+04  1.875800e+04  \n",
       "mean   3.325142e+06  3.732466e+06  4.531389e+05  \n",
       "std    1.347430e+07  1.390155e+07  2.785573e+06  \n",
       "min    0.000000e+00 -1.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00 -1.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00 -1.000000e+00  0.000000e+00  \n",
       "75%    3.333185e+06  4.696002e+06  0.000000e+00  \n",
       "max    6.000000e+08  6.001097e+08  1.680000e+08  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
